{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b427aba-44ac-4a3b-84a1-234ef02a33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "import geoip2.database\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a843cc-b2d0-4e67-a18d-bf3def6e5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === REGEX DEFINITIONS ===\n",
    "ip_regex = re.compile(r'\\d+\\.\\d+\\.\\d+\\.\\d+')\n",
    "\n",
    "timestamp_authlog = re.compile(r'[A-Za-z]{3}\\s+\\d+\\s\\d+:\\d+:\\d+')\n",
    "user_regex = re.compile(r'for (?:invalid user\\s)?(\\w+) from')\n",
    "action_regex = re.compile(r'sshd\\[\\d+\\]:\\s(\\w+\\s\\w+)')\n",
    "port_regex = re.compile(r'port\\s+(\\d+)')\n",
    "service_regex = re.compile(r'(\\w+)$')\n",
    "\n",
    "timestamp_nginx = re.compile(r'\\[(\\d{2}/[A-Za-z]{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2})')\n",
    "http_method_regex = re.compile(r'(GET|POST|DELETE|HEAD|OPTIONS|PATCH)')\n",
    "status_regex = re.compile(r'\"\\s(\\d{3})\\s')\n",
    "path_regex = re.compile(r'\"[A-Z]+\\s([^\\s]+)\\sHTTP')\n",
    "\n",
    "log_pattern_fw = re.compile(\n",
    "    r'^(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+'\n",
    "    r'(ALLOW|DENY)\\s+'\n",
    "    r'(TCP|UDP)\\s+'\n",
    "    r'(\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+'\n",
    "    r'(\\d+)\\s+->\\s+'\n",
    "    r'(\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+'\n",
    "    r'(\\d+)'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32216d8a-89f4-4d92-a9be-08270c124b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PARSERS ===\n",
    "\n",
    "def parse_authlog_line(line):\n",
    "    parsed = {'log_type': 'authlog'}\n",
    "    \n",
    "    ts_match = timestamp_authlog.search(line)\n",
    "    if ts_match:\n",
    "        parsed['timestamp'] = ts_match.group().strip()\n",
    "       \n",
    "    # Extract IP Address\n",
    "    if ip := ip_regex.search(line):\n",
    "        parsed['src_ip'] = ip.group(0)\n",
    "    if user := user_regex.search(line):\n",
    "        parsed['user'] = user.group(1)\n",
    "    if action := action_regex.search(line):\n",
    "        parsed['action'] = action.group(1)\n",
    "    if port := port_regex.search(line):\n",
    "        parsed['dst_port'] = port.group(1)\n",
    "    if service := service_regex.search(line):\n",
    "        parsed['service'] = service.group(1)\n",
    "   \n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def parse_nginx_line(line):\n",
    "    parsed = {'log_type': 'nginx'}\n",
    "    if ip := ip_regex.search(line):\n",
    "        parsed['src_ip'] = ip.group()\n",
    "    if ts := timestamp_nginx.search(line):\n",
    "        try:\n",
    "            dt = datetime.strptime(ts.group(1), \"%d/%b/%Y:%H:%M:%S\")\n",
    "            parsed['timestamp'] = dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        except ValueError:\n",
    "            parsed['timestamp'] = ts.group(1)\n",
    "    if method := http_method_regex.search(line):\n",
    "        parsed['http_method'] = method.group(1)\n",
    "    if path := path_regex.search(line):\n",
    "        parsed['path'] = path.group(1)\n",
    "    if status := status_regex.search(line):\n",
    "        parsed['status_code'] = status.group(1)\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def parse_firewall_line(line):\n",
    "    parsed = {'log_type': 'firewall'}\n",
    "    match = log_pattern_fw.match(line.strip())\n",
    "    if match:\n",
    "        ts, action, protocol, src_ip, src_port, dst_ip, dst_port = match.groups()\n",
    "        parsed['timestamp'] = datetime.strptime(ts, \"%Y-%m-%d %H:%M:%S\").isoformat() + 'Z'\n",
    "        parsed.update({\n",
    "            'action': action,\n",
    "            'protocol': protocol,\n",
    "            'src_ip': src_ip,\n",
    "            'src_port': int(src_port),\n",
    "            'dst_ip': dst_ip,\n",
    "            'dst_port': int(dst_port)\n",
    "        })\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def parse_file(filepath, parser_func):\n",
    "    parsed_logs = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                parsed_logs.append(parser_func(line))\n",
    "    return parsed_logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179519c-de94-4b5b-ac5a-07b4e65e3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAIN PROCESS ===\n",
    "\n",
    "auth_logs = parse_file('inputs/authlog.txt', parse_authlog_line)\n",
    "nginx_logs = parse_file('inputs/nginx.txt', parse_nginx_line)\n",
    "firewall_logs = parse_file('inputs/firewall.txt', parse_firewall_line)\n",
    "\n",
    "# Combine all logs\n",
    "combined_logs = auth_logs + nginx_logs + firewall_logs\n",
    "\n",
    "# Save separate JSONs\n",
    "with open('outputs/parsed_authlog.json', 'w') as f:\n",
    "    json.dump(auth_logs, f, indent=2)\n",
    "\n",
    "with open('outputs/parsed_nginx.json', 'w') as f:\n",
    "    json.dump(nginx_logs, f, indent=2)\n",
    "\n",
    "with open('outputs/parsed_firewall.json', 'w') as f:\n",
    "    json.dump(firewall_logs, f, indent=2)\n",
    "\n",
    "\n",
    "# Harmonize keys : Ensuring that all keys are present in every dictionary\n",
    "all_keys = set()\n",
    "for log in combined_logs:\n",
    "    all_keys.update(log.keys())\n",
    "print(all_keys)\n",
    "\n",
    "for log in combined_logs:\n",
    "    for key in all_keys:\n",
    "        if key not in log:\n",
    "            log[key] = None\n",
    "\n",
    "with open('outputs/combined_logs.json', 'w') as f:\n",
    "    json.dump(combined_logs, f, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813e504-b03a-4857-ba01-698dd8e4c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GEOIP ENRICHMENT ===\n",
    "reader = geoip2.database.Reader(r'inputs\\GeoLite2-Country_20250509\\GeoLite2-Country_20250509\\GeoLite2-Country.mmdb')\n",
    "def enrich_log_with_country(log):\n",
    "    # Create a copy of the original log to avoid modifying it directly\n",
    "    enriched = log.copy()\n",
    "\n",
    "    # Extract the source IP address from the log\n",
    "    src_ip = log.get('src_ip')\n",
    "\n",
    "    # Check if the source IP exists\n",
    "    if src_ip:\n",
    "        try:\n",
    "            # Use the GeoIP reader to get country information for the source IP\n",
    "            response = reader.country(src_ip)\n",
    "\n",
    "            # Add the country name to the log under a new key\n",
    "            enriched['src_geo_country'] = response.country.name\n",
    "        except Exception:\n",
    "            # If the IP is invalid or not found, set the country as None\n",
    "            enriched['src_geo_country'] = None\n",
    "    else:\n",
    "        # If there's no source IP in the log, set country as None\n",
    "        enriched['src_geo_country'] = None\n",
    "\n",
    "    # Return the enriched log with country information\n",
    "    return enriched\n",
    "\n",
    "\n",
    "\n",
    "enriched_logs = [enrich_log_with_country(log) for log in combined_logs]\n",
    "\n",
    "with open('outputs/enriched_logs.json', 'w') as f:\n",
    "    json.dump(enriched_logs, f, indent=2)\n",
    "\n",
    "print(\"Enrichment complete. Sample:\")\n",
    "print(json.dumps(enriched_logs[:5], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "log_parsing",
   "language": "python",
   "name": "log_parsing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
